{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'time', u'S1', u'S2', u'S3', u'S4', u'S5', u'S6', u'S7', u'S8', u'S9',\n",
       "       u'S10', u'S11', u'S12', u'S13', u'S14', u'S15', u'S16', u'S17', u'S18',\n",
       "       u'S19', u'S20', u'S21', u'S22', u'S23', u'S24', u'S25', u'S26', u'S27',\n",
       "       u'S28', u'S29', u'S30', u'S31', u'S32', u'S33', u'S34', u'S35', u'S36',\n",
       "       u'S37', u'S38', u'S39', u'S40', u'S41', u'S42', u'S43', u'S44', u'S45',\n",
       "       u'S46', u'S47', u'S48', u'S49', u'S50', u'S51', u'S52', u'S53', u'S54',\n",
       "       u'S55', u'S56'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.txt', skipinitialspace=True)\n",
    "df_train.rename(columns={'Timestamp (DHHMM)':'time'}, inplace=True)\n",
    "df_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>S7</th>\n",
       "      <th>S8</th>\n",
       "      <th>S9</th>\n",
       "      <th>...</th>\n",
       "      <th>S47</th>\n",
       "      <th>S48</th>\n",
       "      <th>S49</th>\n",
       "      <th>S50</th>\n",
       "      <th>S51</th>\n",
       "      <th>S52</th>\n",
       "      <th>S53</th>\n",
       "      <th>S54</th>\n",
       "      <th>S55</th>\n",
       "      <th>S56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    time  S1  S2  S3  S4  S5  S6  S7  S8  S9 ...   S47  S48  S49  S50  S51  \\\n",
       "0  10000   0   0   0   0   0   0   0   0   0 ...     0    0    0    0    0   \n",
       "1  10001   0   0   0   0   0   0   0   1   0 ...     0    0    0    0    0   \n",
       "2  10002   0   0   0   0   0   0   0   0   0 ...     0    0    0    0    0   \n",
       "3  10003   0   0   0   0   0   0   0   0   0 ...     0    0    0    0    0   \n",
       "4  10004   0   0   0   0   0   0   0   0   0 ...     0    0    0    0    0   \n",
       "\n",
       "   S52  S53  S54  S55  S56  \n",
       "0    0    0    0    0    0  \n",
       "1    0    0    0    0    0  \n",
       "2    0    0    0    0    0  \n",
       "3    0    0    0    0    0  \n",
       "4    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sort(u'time')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converts time stamp as int in DHHMM into index for the table\n",
    "def timestamptoindex(ts):\n",
    "    mm = ts % 100\n",
    "    hh = (ts % (100 * 100)) // 100\n",
    "    d = ts // (100 * 100)\n",
    "    \n",
    "    index = mm + 60 * hh + 60 * 24 * (d - 1)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamptoindex(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no exception means, functions works alright!\n",
    "for i, row in df_train.iterrows():\n",
    "    assert timestamptoindex(row[u'time']) == i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Linear model for one sensor only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'time', u'S1', u'S2', u'S3', u'S4', u'S5', u'S6', u'S7', u'S8', u'S9',\n",
       "       u'S10', u'S11', u'S12', u'S13', u'S14', u'S15', u'S16', u'S17', u'S18',\n",
       "       u'S19', u'S20', u'S21', u'S22', u'S23', u'S24', u'S25', u'S26', u'S27',\n",
       "       u'S28', u'S29', u'S30', u'S31', u'S32', u'S33', u'S34', u'S35', u'S36',\n",
       "       u'S37', u'S38', u'S39', u'S40', u'S41', u'S42', u'S43', u'S44', u'S45',\n",
       "       u'S46', u'S47', u'S48', u'S49', u'S50', u'S51', u'S52', u'S53', u'S54',\n",
       "       u'S55', u'S56'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0610340169471\n",
      "2485/40715 missing\n"
     ]
    }
   ],
   "source": [
    "# want to predict for the missing, use the valid ones as trainset\n",
    "missing_percentage = 1. * df_train_missing.count()[0] / df_train_valid.count()[0]\n",
    "print missing_percentage\n",
    "print str(df_train_missing.count()[0]) + '/' + str(df_train_valid.count()[0]) + ' missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sklearn functions used for the linear regression model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(df_train['S1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  1,  5,  3,  4,  6,  7,  9, 14, 10,  8, 17, 15, 20, 30, 16,\n",
       "       23, 18, 19, -1, 11, 13, 26, 12])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['S1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## function to compute results for a basic multinomial, logistic model\n",
    "def MultinomialTimeModel(df):\n",
    "    dfout = df.copy()\n",
    "    \n",
    "    # extract time feature\n",
    "    #df['btime'] = (df['time'] % (100 * 100)) // 100\n",
    "    # extract time feature (5minute features!)\n",
    "    df['btime'] = (df['time'] % (100 * 100)) // 100 * 100 + ((df['time'] % 100) // 5) * 5\n",
    "    \n",
    "    # encode btime as categorical features\n",
    "    encoder = OneHotEncoder(sparse=True) \n",
    "    categoricalFeat = df['btime']\n",
    "    categoricals_encoded = encoder.fit_transform(categoricalFeat.reshape(-1, 1))\n",
    "\n",
    "    # for each sensor, build a logistic regression model based on the time\n",
    "    num_sensors = 56\n",
    "    for i in xrange(num_sensors):\n",
    "        sid = 'S' + str(i+1)\n",
    "        print 'predicting ' + sid + ' missing data...'\n",
    "\n",
    "        idx_missing = df[sid] < 0\n",
    "\n",
    "        X_train = categoricals_encoded.toarray()[np.array(~idx_missing), :]\n",
    "        X_test = categoricals_encoded.toarray()[np.array(idx_missing), :]\n",
    "        y_train, y_test = df[sid][~idx_missing], df[sid][idx_missing]\n",
    "\n",
    "        # check if errors exist, if not skip next steps!\n",
    "        if y_test.shape[0] == 0:\n",
    "            print sid + ' has no errors!'\n",
    "            continue\n",
    "        \n",
    "        clf = sklearn.linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "\n",
    "        # fit the model!\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # update the entries according to the model\n",
    "        dfout[sid][idx_missing] = y_pred\n",
    "    print 'done!'\n",
    "    return dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting S1 missing data...\n",
      "predicting S2 missing data...\n",
      "predicting S3 missing data...\n",
      "predicting S4 missing data...\n",
      "predicting S5 missing data...\n",
      "predicting S6 missing data...\n",
      "predicting S7 missing data...\n",
      "predicting S8 missing data...\n",
      "predicting S9 missing data...\n",
      "predicting S10 missing data...\n",
      "predicting S11 missing data...\n",
      "predicting S12 missing data...\n",
      "predicting S13 missing data...\n",
      "predicting S14 missing data...\n",
      "predicting S15 missing data...\n",
      "predicting S16 missing data...\n",
      "predicting S17 missing data...\n",
      "predicting S18 missing data...\n",
      "predicting S19 missing data...\n",
      "predicting S20 missing data...\n",
      "predicting S21 missing data...\n",
      "predicting S22 missing data...\n",
      "predicting S23 missing data...\n",
      "predicting S24 missing data...\n",
      "predicting S25 missing data...\n",
      "predicting S26 missing data...\n",
      "predicting S27 missing data...\n",
      "predicting S28 missing data...\n",
      "predicting S29 missing data...\n",
      "predicting S30 missing data...\n",
      "predicting S31 missing data...\n",
      "predicting S32 missing data...\n",
      "predicting S33 missing data...\n",
      "predicting S34 missing data...\n",
      "predicting S35 missing data...\n",
      "predicting S36 missing data...\n",
      "predicting S37 missing data...\n",
      "predicting S38 missing data...\n",
      "predicting S39 missing data...\n",
      "predicting S40 missing data...\n",
      "predicting S41 missing data...\n",
      "predicting S42 missing data...\n",
      "predicting S43 missing data...\n",
      "predicting S44 missing data...\n",
      "predicting S45 missing data...\n",
      "predicting S46 missing data...\n",
      "predicting S47 missing data...\n",
      "S47 has no errors!\n",
      "predicting S48 missing data...\n",
      "predicting S49 missing data...\n",
      "predicting S50 missing data...\n",
      "predicting S51 missing data...\n",
      "predicting S52 missing data...\n",
      "predicting S53 missing data...\n",
      "predicting S54 missing data...\n",
      "predicting S55 missing data...\n",
      "predicting S56 missing data...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# OUPUT RESULTS TO FILE\n",
    "dfout = MultinomialTimeModel(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission_file(dfout, 'multilog.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
