{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats.mstats import mode\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import time\n",
    "%matplotlib inline\n",
    "from helper import *\n",
    "from IDWmodel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Building a reference table with average daily value of the sensor\n",
    "# specify with num_minutes over how many minutes the time should be bucketed\n",
    "def build_avg_time_table(df_train, num_minutes=5):\n",
    "    \n",
    "    # different averaging does not seem to have an effect...\n",
    "    df_train['day_time'] = (df_train['time'] % (100 * 100)) // 100 * 100 + ((df_train['time'] % 100) // num_minutes) * num_minutes\n",
    "    \n",
    "    # Initializing the dataframe\n",
    "    # Update: rounding the value\n",
    "    col_name = 'S1'\n",
    "    df_day_avg_values = df_train[[col_name, 'day_time']][df_train[col_name] != -1].groupby('day_time').mean().apply(pd.Series.round)\n",
    "\n",
    "    col_names = ['S'+str(i) for i in xrange(1, 57)]\n",
    "    for col_name in col_names[1:]:\n",
    "        df_day_avg_values = df_day_avg_values.join(df_train[[col_name, 'day_time']][df_train[col_name] != -1].groupby('day_time').mean().apply(pd.Series.round))\n",
    "        \n",
    "    return df_day_avg_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = load_train_data()\n",
    "df_IDWmodel = pd.read_csv('data/IDWmodel_train.csv')\n",
    "df_day_avg_values = build_avg_time_table(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "def prediction(df_train, col_names, df_day_avg_values, adjacency_list, df_model, prediction_model, do_rounding = False):\n",
    "    # add staircase/restroom binary features\n",
    "    # augment manually\n",
    "    staircaseA_nodes = ['S42', 'S46']\n",
    "    staircaseB_nodes = ['S34', 'S35']\n",
    "    staircaseC_nodes = ['S52', 'S53']\n",
    "    \n",
    "    # Dataframe to store the model prediction\n",
    "    df_model_lr = df_train.copy()\n",
    "    \n",
    "    for col in col_names:\n",
    "        # X will store the features and the outcome Y\n",
    "        X = df_train.copy()\n",
    "        X = X.rename(columns={col:'Y'})\n",
    "        X = pd.merge(X, df_day_avg_values[[col]], left_on='day_time', right_index=True)\n",
    "        X = X.rename(columns={col:col+'avg'})\n",
    "\n",
    "        # Building the neighbors (from adjacency list) with missing values filled as in model\n",
    "        neighbors_col = ['S'+str(n) for n in adjacency_list[int(col[1:])]]\n",
    "        X = X[['Y']].join(df_model[neighbors_col])\n",
    "        \n",
    "        # augment with staircase info\n",
    "        X['sA'] = (col in staircaseA_nodes) * 1.\n",
    "        X['sB'] = (col in staircaseB_nodes) * 1.\n",
    "        X['sC'] = (col in staircaseC_nodes) * 1.\n",
    "        \n",
    "\n",
    "        X_train = X[X['Y'] != -1]\n",
    "        X_test = X[X['Y'] == -1]\n",
    "        test_indices = X[X['Y'] == -1].index\n",
    "        col_values = X['Y']\n",
    "\n",
    "        if len(X_test):\n",
    "            # Models\n",
    "            prediction_model = prediction_model.fit(X_train.drop('Y', axis=1), X_train.Y)\n",
    "            col_values.ix[test_indices] = prediction_model.predict(X_test.drop('Y', axis=1))\n",
    "\n",
    "            # Filling the result with the current sensor prediction\n",
    "            if do_rounding:\n",
    "                df_model_lr[col] = np.round(col_values)\n",
    "            else:\n",
    "                df_model_lr[col] = col_values\n",
    "    return df_model_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_names = ['S'+str(i) for i in xrange(1, 57)]\n",
    "adjacency_list = compute_adjlist(27.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A value in x_new is below the interpolation range.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-244-787d56421d2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLassoLarsCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_model_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_day_avg_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjacency_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_IDWmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_day_avg_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_avg_time_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_model_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_model_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_day_avg_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjacency_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_model_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_day_avg_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_avg_time_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_model_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-242-f8ede792e92a>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(df_train, col_names, df_day_avg_values, adjacency_list, df_model, prediction_model, do_rounding)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# Models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mprediction_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mcol_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py27/lib/python2.7/site-packages/sklearn/linear_model/least_angle.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1111\u001b[0m             this_residues = interpolate.interp1d(alphas,\n\u001b[1;32m   1112\u001b[0m                                                  \u001b[0mresidues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                                                  axis=0)(all_alphas)\n\u001b[0m\u001b[1;32m   1114\u001b[0m             \u001b[0mthis_residues\u001b[0m \u001b[0;34m**=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0mmse_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_residues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py27/lib/python2.7/site-packages/scipy/interpolate/polyint.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \"\"\"\n\u001b[1;32m     78\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py27/lib/python2.7/site-packages/scipy/interpolate/interpolate.pyc\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, x_new)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m#    The behavior is set by the bounds_error variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mx_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0mout_of_bounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0my_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py27/lib/python2.7/site-packages/scipy/interpolate/interpolate.pyc\u001b[0m in \u001b[0;36m_check_bounds\u001b[0;34m(self, x_new)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;31m# !! Could provide more information about which values are out of bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbelow_bounds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             raise ValueError(\"A value in x_new is below the interpolation \"\n\u001b[0m\u001b[1;32m    525\u001b[0m                 \"range.\")\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mabove_bounds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A value in x_new is below the interpolation range."
     ]
    }
   ],
   "source": [
    "clf = linear_model.LassoLarsCV(positive=True, max_iter=1500)\n",
    "df_model_lr = prediction(df_train, col_names, df_day_avg_values, adjacency_list, df_IDWmodel, clf)\n",
    "df_day_avg_values = build_avg_time_table(df_model_lr)\n",
    "df_model_lr = prediction(df_train, col_names, df_day_avg_values, adjacency_list, df_model_lr, clf)\n",
    "df_day_avg_values = build_avg_time_table(df_model_lr)\n",
    "df_model_lr = prediction(df_train, col_names, df_day_avg_values, adjacency_list, df_model_lr, clf)\n",
    "df_day_avg_values = build_avg_time_table(df_model_lr)\n",
    "df_model_lr = prediction(df_train, col_names, df_day_avg_values, adjacency_list, df_model_lr, clf)\n",
    "df_day_avg_values = build_avg_time_table(df_model_lr)\n",
    "df_model_lr = prediction(df_train, col_names, df_day_avg_values, adjacency_list, df_model_lr, clf)\n",
    "df_day_avg_values = build_avg_time_table(df_model_lr)\n",
    "df_model_lr = prediction(df_train, col_names, df_day_avg_values, adjacency_list, df_model_lr, clf)\n",
    "df_day_avg_values = build_avg_time_table(df_model_lr)\n",
    "df_model_lr = prediction(df_train, col_names, df_day_avg_values, adjacency_list, df_model_lr, clf, do_rounding = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission_file(df_model_lr, 'models/lr_model_leo_v7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_augmented(df_train, col_names, df_day_avg_values, adjacency_list, df_model, prediction_model, window_size=10, do_rounding = False):\n",
    "    staircaseA_nodes = ['S42', 'S46']\n",
    "    staircaseB_nodes = ['S34', 'S35']\n",
    "    staircaseC_nodes = ['S52', 'S53']\n",
    "    \n",
    "    # Dataframe to store the model prediction\n",
    "    df_model_lr = df_model.copy()\n",
    "    \n",
    "    # Building the moving sum for the features before/after for each neighbor\n",
    "    model_curr_before = pd.rolling_sum(df_model.sort(ascending=False), window_size+1) - df_model\n",
    "    model_curr_after = pd.rolling_sum(df_model, window_size+1) - df_model\n",
    "    model_curr_before = model_curr_before.rename(columns={col:col+'before' for col in col_names})\n",
    "    model_curr_after = model_curr_after.rename(columns={col:col+'after' for col in col_names})\n",
    "    window_features = model_curr_after.join(model_curr_before[[col_+'before' for col_ in col_names]])\n",
    "    \n",
    "    for col in col_names:\n",
    "        # X will store the features and the outcome Y\n",
    "        X = df_train.copy()\n",
    "        X = X.rename(columns={col:'Y'})\n",
    "        X = pd.merge(X, df_day_avg_values[[col]], left_on='day_time', right_index=True)\n",
    "        X = X.rename(columns={col:col+'avg'})\n",
    "\n",
    "        # Building the neighbors (from adjacency list) with missing values filled as in model\n",
    "        neighbors_col = ['S'+str(n) for n in adjacency_list[int(col[1:])]]\n",
    "        \n",
    "        X = X[['Y']].join(df_model[neighbors_col])\n",
    "        X = X.join(window_features[[col_+'before' for col_ in neighbors_col] + [col_+'after' for col_ in neighbors_col]])\n",
    "        # Removing the first and last element impossible to compute given the window_size\n",
    "        X = X.sort()[window_size: - window_size]\n",
    "        \n",
    "        # augment with staircase info\n",
    "        X['sA'] = (col in staircaseA_nodes) * 1.\n",
    "        X['sB'] = (col in staircaseB_nodes) * 1.\n",
    "        X['sC'] = (col in staircaseC_nodes) * 1.\n",
    "\n",
    "        X_train = X[X['Y'] != -1]\n",
    "        X_test = X[X['Y'] == -1]\n",
    "        test_indices = X[X['Y'] == -1].index\n",
    "        col_values = df_model_lr[col]\n",
    "\n",
    "        if len(X_test):\n",
    "            # Models\n",
    "            prediction_model = prediction_model.fit(X_train.drop('Y', axis=1), X_train.Y)\n",
    "            col_values.ix[test_indices] = prediction_model.predict(X_test.drop('Y', axis=1))\n",
    "\n",
    "            # Filling the result with the current sensor prediction\n",
    "            if do_rounding:\n",
    "                df_model_lr[col] = np.round(col_values)\n",
    "            else:\n",
    "                df_model_lr[col] = col_values\n",
    "    return df_model_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: sort(....) is deprecated, use sort_index(.....)\n",
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:29: FutureWarning: sort(....) is deprecated, use sort_index(.....)\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.LassoLarsCV(positive=True, max_iter=1500)\n",
    "\n",
    "#clf = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])\n",
    "#clf = linear_model.BayesianRidge()\n",
    "#clf = Pipeline([('poly', PolynomialFeatures(degree=3)), ('linear', linear_model.LassoLarsCV(fit_intercept=False))])\n",
    "adjacency_list_leo_tuned = adjacency_list\n",
    "df_model_lr_v7 = prediction_augmented(df_train, col_names, df_day_avg_values, adjacency_list_leo_tuned, df_IDWmodel, clf, window_size=10)\n",
    "df_model_lr_v7 = prediction_augmented(df_train, col_names, df_day_avg_values, adjacency_list_leo_tuned, df_model_lr_v7, clf, window_size=10)\n",
    "df_model_lr_v7 = prediction_augmented(df_train, col_names, df_day_avg_values, adjacency_list_leo_tuned, df_model_lr_v7, clf, window_size=10)\n",
    "df_model_lr_v7 = prediction_augmented(df_train, col_names, df_day_avg_values, adjacency_list_leo_tuned, df_model_lr_v7, clf, window_size=10)\n",
    "df_model_lr_v7 = prediction_augmented(df_train, col_names, df_day_avg_values, adjacency_list_leo_tuned, df_model_lr_v7, clf, window_size=10)\n",
    "df_model_lr_v7 = prediction_augmented(df_train, col_names, df_day_avg_values, adjacency_list_leo_tuned, df_model_lr_v7, clf, window_size=10)\n",
    "df_model_lr_v7 = prediction_augmented(df_train, col_names, df_day_avg_values, adjacency_list_leo_tuned, df_model_lr_v7, clf, window_size=10, do_rounding = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission_file(df_model_lr_v7, 'models/lr_model_leo_v8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot how much data for each sensor is missing in %\n",
    "for i in xrange(56):\n",
    "    sid = 'S'+str(i+1)\n",
    "    idxs = df[sid] == -1\n",
    "    print sid + ' ' + str(np.sum(idxs * 1.) / (1. * df.count()[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
