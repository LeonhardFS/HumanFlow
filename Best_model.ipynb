{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats.mstats import mode\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import time\n",
    "%matplotlib inline\n",
    "from helper import *\n",
    "from IDWmodel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot how much data for each sensor is missing in %\n",
    "def compute_missing_entries_per_day(df, num_days):\n",
    "    missing_per_day = {}\n",
    "    for day in xrange(1, num_days + 1):\n",
    "        print 'processing day {} ...'.format(day)\n",
    "        daydict = {}\n",
    "        for i in xrange(56):\n",
    "            sid = 'S'+str(i+1)\n",
    "            df_day = df[df['day'] == day]\n",
    "            idxs = df_day[sid] == -1\n",
    "            daydict[sid] = np.sum(idxs * 1.) / (1. * df_day.count()[0])\n",
    "        missing_per_day[day] = daydict\n",
    "    return missing_per_day\n",
    "\n",
    "def wavg(val_col_name,wt_col_name):\n",
    "    def inner(group):\n",
    "        val = (group[val_col_name] * group[wt_col_name]).sum() / group[wt_col_name].sum()\n",
    "        return np.round(val)\n",
    "    inner.__name__ = 'wgt_avg'\n",
    "    return inner    \n",
    "\n",
    "# ### Building a reference table with average daily value of the sensor\n",
    "# specify with num_minutes over how many minutes the time should be bucketed\n",
    "def build_weighted_time_table(df_train, num_minutes=5):\n",
    "    # different averaging does not seem to have an effect...\n",
    "    df_train['day'] =  df_train['time'] // 10000\n",
    "    df_train['day_time'] = (df_train['time'] % (100 * 100)) // 100 * 100 + ((df_train['time'] % 100) // num_minutes) * num_minutes\n",
    "    \n",
    "    num_days = int(df_train.day.max())\n",
    "    missing_per_day = compute_missing_entries_per_day(df_train, num_days)\n",
    "    \n",
    "    # augment using the missing entries\n",
    "    for i in xrange(56):\n",
    "        sid = 'S'+str(i+1)\n",
    "        wid = 'w'+str(i+1)\n",
    "        df_train[wid] = 0.\n",
    "        for day in xrange(1, num_days+1):\n",
    "            df_train.loc[df_train['day'] == day, wid] = 1. - missing_per_day[day][sid]\n",
    "    \n",
    "    # normalize weights, so they sum up to 1!\n",
    "    # assert here that there are num_days rows!\n",
    "    df_normalizer = df_train[df_train['time'] % 10000 == 0]\n",
    "    assert(df_normalizer.count()[0] == num_days)\n",
    "\n",
    "    for i in xrange(56):\n",
    "        wid = 'w'+str(i+1)\n",
    "        df_train[wid] /= df_normalizer.sum()[wid] * 1.\n",
    "        \n",
    "        \n",
    "    # Initializing the dataframe\n",
    "    # Update: rounding the value is done in the wavg function, should be maybe adjusted!\n",
    "    col_name = 'S1'\n",
    "    wid = 'w1'\n",
    "    df_day_avg_values = pd.DataFrame(df_train[[col_name, 'day_time', wid]][df_train[col_name] != -1].groupby('day_time').apply(wavg(col_name, wid)), columns=[col_name])\n",
    "    df_day_avg_values\n",
    "    for i in xrange(1, 56):\n",
    "        col_name = 'S'+str(i+1)\n",
    "        wid = 'w'+str(i+1)\n",
    "        print 'processing '+col_name\n",
    "        df_day_frame = pd.DataFrame(df_train[[col_name, 'day_time', wid]][df_train[col_name] != -1].groupby('day_time').apply(wavg(col_name, wid)), columns=[col_name])\n",
    "        df_day_avg_values = df_day_avg_values.join(df_day_frame)\n",
    "        \n",
    "    return df_day_avg_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing day 1 ...\n",
      "processing day 2 ...\n",
      "processing day 3 ...\n",
      "processing day 4 ...\n",
      "processing day 5 ...\n",
      "processing day 6 ...\n",
      "processing day 7 ...\n",
      "processing day 8 ...\n",
      "processing day 9 ...\n",
      "processing day 10 ...\n",
      "processing day 11 ...\n",
      "processing day 12 ...\n",
      "processing day 13 ...\n",
      "processing day 14 ...\n",
      "processing day 15 ...\n",
      "processing day 16 ...\n",
      "processing day 17 ...\n",
      "processing day 18 ...\n",
      "processing day 19 ...\n",
      "processing day 20 ...\n",
      "processing day 21 ...\n",
      "processing day 22 ...\n",
      "processing day 23 ...\n",
      "processing day 24 ...\n",
      "processing day 25 ...\n",
      "processing day 26 ...\n",
      "processing day 27 ...\n",
      "processing day 28 ...\n",
      "processing day 29 ...\n",
      "processing day 30 ...\n",
      "processing S2\n",
      "processing S3\n",
      "processing S4\n",
      "processing S5\n",
      "processing S6\n",
      "processing S7\n",
      "processing S8\n",
      "processing S9\n",
      "processing S10\n",
      "processing S11\n",
      "processing S12\n",
      "processing S13\n",
      "processing S14\n",
      "processing S15\n",
      "processing S16\n",
      "processing S17\n",
      "processing S18\n",
      "processing S19\n",
      "processing S20\n",
      "processing S21\n",
      "processing S22\n",
      "processing S23\n",
      "processing S24\n",
      "processing S25\n",
      "processing S26\n",
      "processing S27\n",
      "processing S28\n",
      "processing S29\n",
      "processing S30\n",
      "processing S31\n",
      "processing S32\n",
      "processing S33\n",
      "processing S34\n",
      "processing S35\n",
      "processing S36\n",
      "processing S37\n",
      "processing S38\n",
      "processing S39\n",
      "processing S40\n",
      "processing S41\n",
      "processing S42\n",
      "processing S43\n",
      "processing S44\n",
      "processing S45\n",
      "processing S46\n",
      "processing S47\n",
      "processing S48\n",
      "processing S49\n",
      "processing S50\n",
      "processing S51\n",
      "processing S52\n",
      "processing S53\n",
      "processing S54\n",
      "processing S55\n",
      "processing S56\n"
     ]
    }
   ],
   "source": [
    "df_train = load_train_data()\n",
    "df_IDWmodel = pd.read_csv('data/IDWmodel_train.csv')\n",
    "df_day_avg_values = build_weighted_time_table(df_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
